// DATE : 05/14/15
// FILE : Robot_filter.cpp
// DESC : Class to read robot.txt files and identify URLs that should be excluded from index

// LEFT OFF //
/*
 */

// BUGS //
/*
 */

// POSSIBLE SOLUTIONS/ADDITIONS //
/*
 */

// NOTES //
/*
 */

class Robot_filter {
public :

// CONSTRUCTORS //
Robot_filter() {}

// MEMBER FUNCTIONS //

// PRECONDITIONS :
// POSTCONDITIONS :
bool get_excluded(  istream & input) {  }

// PRECONDITIONS :
// POSTCONDITIONS :
bool is_exclueded(const char *url) {  }
};
